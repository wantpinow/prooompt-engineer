{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='MESSAGE_START', value='system')\n",
      "Token(type='TEXT', value='You are a genius')\n",
      "Token(type='ENDMESSAGE', value='{% endmessage %}')\n",
      "Token(type='MESSAGE_START', value='user')\n",
      "Token(type='TEXT', value='My name is')\n",
      "Token(type='EXPRESSION', value='name')\n",
      "Token(type='TEXT', value='. What is my name?')\n",
      "Token(type='ENDMESSAGE', value='{% endmessage %}')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import namedtuple\n",
    "\n",
    "# Defining a simple token structure\n",
    "Token = namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "# Token definitions\n",
    "TOKEN_REGEX = re.compile(r\"\"\"\n",
    "    (\\{\\%\\s*endmessage\\s*\\%\\})|    # End of a message block\n",
    "    (\\{\\%\\s*message\\s+[a-z]+\\s*\\%\\})| # Start of a message block with role\n",
    "    (\\{\\%\\s*endfor\\s*\\%\\})|        # End of a loop\n",
    "    (\\{\\%\\s*for\\s+.+?\\s+in\\s+.+?\\s*\\%\\})| # Start of a loop\n",
    "    (\\{\\{.+?\\}\\})|                 # Expression\n",
    "    (\\{\\%.*?\\%\\})|                 # Other tag (for future use)\n",
    "    ([^{]+)                        # Text\n",
    "    \"\"\", re.VERBOSE)\n",
    "\n",
    "# Token types\n",
    "TOKEN_TYPES = [\n",
    "    ('ENDMESSAGE', 'endmessage'),\n",
    "    ('MESSAGE_START', 'message'),\n",
    "    ('ENDFOR', 'endfor'),\n",
    "    ('FOR', 'for'),\n",
    "    ('EXPRESSION', 'expression'),\n",
    "    ('TAG', 'tag'),\n",
    "    ('TEXT', 'text'),\n",
    "]\n",
    "\n",
    "def tokenize(text) -> list[Token]:\n",
    "    tokens = []\n",
    "    for match in TOKEN_REGEX.finditer(text):\n",
    "        match_groups = match.groups()\n",
    "        for i, group in enumerate(match_groups):\n",
    "            if group:\n",
    "                # Determine the type based on which group matched\n",
    "                token_type = TOKEN_TYPES[i][0]\n",
    "                token_value = group.strip()\n",
    "                \n",
    "                # Special handling for message and for tags to include additional info\n",
    "                if token_type in ['MESSAGE_START', 'FOR']:\n",
    "                    # Extracting role for MESSAGE_START or loop variables for FOR\n",
    "                    token_value = re.sub(r\"^\\{\\%\\s*|\\s*\\%\\}$\", \"\", token_value) # Remove the tag delimiter\n",
    "                    if token_type == 'MESSAGE_START':\n",
    "                        token_value = token_value.split(' ')[1]\n",
    "                \n",
    "                if token_type == 'EXPRESSION':\n",
    "                    # remove the {{ and }} delimiters\n",
    "                    token_value = token_value[2:-2].strip()\n",
    "\n",
    "                tokens.append(Token(token_type, token_value))\n",
    "                break\n",
    "    # filter out text tokens that are empty\n",
    "    tokens = [token for token in tokens if token.type != 'TEXT' or token.value]\n",
    "    return tokens\n",
    "\n",
    "# Example usage\n",
    "example_text = \"\"\"\n",
    "{% message system %}\n",
    "You are a genius\n",
    "{% endmessage %}\n",
    "\n",
    "{% message user %}\n",
    "My name is {{name}}. What is my name?\n",
    "{% endmessage %}\n",
    "\"\"\"\n",
    "\n",
    "tokens = tokenize(example_text)\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"type\": \"message\",\n",
      "      \"role\": \"system\",\n",
      "      \"template\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"You are a genius\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"content\": \"You are a genius\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"message\",\n",
      "      \"role\": \"user\",\n",
      "      \"template\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \"My name is\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"eval\",\n",
      "          \"value\": \"name\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"content\": \". What is my name?\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"content\": \"My name is\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"eval\",\n",
      "      \"value\": \"name\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"content\": \". What is my name?\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from prooompt.datatypes import Template, TemplateItem, TemplateItemUnion, TemplateMessage, MessageRole, TemplateText, TemplateEval, TemplateLoop\n",
    "\n",
    "def parse(tokens: list[Token]) -> Template:\n",
    "    items = parse_template_items(tokens)\n",
    "    return Template(items=items)\n",
    "\n",
    "def parse_template_items(tokens: list[Token]) -> list[TemplateItemUnion]:\n",
    "    token_types = [token.type for token in tokens]\n",
    "    parsed = []\n",
    "    for token_idx in range(len(tokens)):\n",
    "        token = tokens[token_idx]\n",
    "        if token.type == \"MESSAGE_START\":\n",
    "            # Extract the role from the message start token\n",
    "            role = token.value\n",
    "\n",
    "            # Get the tokens between the message start and endmessage tokens\n",
    "            message_end_idx = token_types[token_idx:].index(\"ENDMESSAGE\")\n",
    "            message_tokens = tokens[token_idx+1:token_idx+message_end_idx]\n",
    "\n",
    "            message = TemplateMessage(role=MessageRole(role), template=parse_template_items(message_tokens))\n",
    "            parsed.append(message)\n",
    "        \n",
    "        elif token.type == \"FOR\":\n",
    "            raise NotImplementedError(\"For loops are not yet supported\")\n",
    "    \n",
    "        elif token.type == \"EXPRESSION\":\n",
    "            parsed.append(TemplateEval(value=token.value))\n",
    "        \n",
    "        elif token.type == \"TEXT\":\n",
    "            parsed.append(TemplateText(content=token.value))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "print(parse(tokens).model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ARE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 100\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (TemplateLoop(iterator\u001b[38;5;241m=\u001b[39miterator, iterable\u001b[38;5;241m=\u001b[39miterable, template\u001b[38;5;241m=\u001b[39mloop_items), consumed_tokens)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Now, use the parser function on the list of tokens from step 1\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m template_structure \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(template_structure\u001b[38;5;241m.\u001b[39mmodel_dump_json(indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(tokens):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Parses the list of tokens and returns the structured Pydantic model.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     template_items \u001b[38;5;241m=\u001b[39m \u001b[43mparse_template_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Template(items\u001b[38;5;241m=\u001b[39mtemplate_items)\n",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mparse_template_items\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     20\u001b[0m token \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMESSAGE_START\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     message, consumed_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mparse_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     items\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m     25\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[consumed_tokens:]\n",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m, in \u001b[0;36mparse_message\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     65\u001b[0m     consumed_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     66\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (TemplateMessage(role\u001b[38;5;241m=\u001b[39m\u001b[43mMessageRole\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, template\u001b[38;5;241m=\u001b[39mmessage_items), consumed_tokens)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/enum.py:801\u001b[0m, in \u001b[0;36mEnumType.__getitem__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name):\n\u001b[1;32m    798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03m    Return the member matching `name`.\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_member_map_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ARE'"
     ]
    }
   ],
   "source": [
    "from prooompt.datatypes import Template, TemplateItem, TemplateItemUnion, TemplateMessage, MessageRole, TemplateText, TemplateEval, TemplateLoop\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "# Assuming 'tokens' is the list of tokens produced by the lexer for the given text\n",
    "\n",
    "def parse(tokens):\n",
    "    \"\"\"\n",
    "    Parses the list of tokens and returns the structured Pydantic model.\n",
    "    \"\"\"\n",
    "    template_items = parse_template_items(tokens)\n",
    "    return Template(items=template_items)\n",
    "\n",
    "def parse_template_items(tokens) -> List[TemplateItemUnion]:\n",
    "    \"\"\"\n",
    "    Parses template items, recursively handling nested structures.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    while tokens:\n",
    "        token = tokens.pop(0)\n",
    "        \n",
    "        if token.type == 'MESSAGE_START':\n",
    "            message, consumed_tokens = parse_message(tokens)\n",
    "            items.append(message)\n",
    "            tokens = tokens[consumed_tokens:]\n",
    "        \n",
    "        elif token.type == 'FOR':\n",
    "            loop, consumed_tokens = parse_for_loop(tokens)\n",
    "            items.append(loop)\n",
    "            tokens = tokens[consumed_tokens:]\n",
    "        \n",
    "        elif token.type == 'TEXT':\n",
    "            if token.value.strip():  # Ignore purely whitespace texts\n",
    "                items.append(TemplateText(content=token.value))\n",
    "        \n",
    "        elif token.type == 'EXPRESSION':\n",
    "            expression_value = re.sub(r\"^\\{\\{|\\}\\}$\", \"\", token.value)  # Remove the expression delimiters\n",
    "            items.append(TemplateEval(value=expression_value))\n",
    "    \n",
    "    return items\n",
    "\n",
    "def parse_message(tokens) -> tuple[TemplateMessage, int]:\n",
    "    \"\"\"\n",
    "    Parses a message block, collecting contained template items.\n",
    "    \"\"\"\n",
    "    role = tokens.pop(0).value.split()[1]  # Extract the role from the 'message <role>' format\n",
    "    message_items = []\n",
    "    consumed_tokens = 0\n",
    "    \n",
    "    while tokens and tokens[0].type != 'ENDMESSAGE':\n",
    "        token = tokens.pop(0)\n",
    "        consumed_tokens += 1\n",
    "        \n",
    "        if token.type == 'TEXT' or token.type == 'EXPRESSION':\n",
    "            # Place the token back and let parse_template_items handle it\n",
    "            tokens.insert(0, token)\n",
    "            nested_items = parse_template_items(tokens)\n",
    "            message_items.extend(nested_items)\n",
    "            # Update consumed_tokens based on the number of tokens processed inside parse_template_items\n",
    "            consumed_tokens += len(nested_items)\n",
    "        # Extend this to handle nested loops or other structures\n",
    "    \n",
    "    # Skip the ENDMESSAGE token\n",
    "    if tokens and tokens[0].type == 'ENDMESSAGE':\n",
    "        consumed_tokens += 1\n",
    "        tokens.pop(0)\n",
    "    \n",
    "    return (TemplateMessage(role=MessageRole[role.upper()], template=message_items), consumed_tokens)\n",
    "\n",
    "def parse_for_loop(tokens) -> tuple[TemplateLoop, int]:\n",
    "    \"\"\"\n",
    "    Parses a for-loop, including its templated content.\n",
    "    \"\"\"\n",
    "    loop_start_token = tokens.pop(0)\n",
    "    iterator, iterable = re.match(r\"for (.+?) in (.+)\", loop_start_token.value).groups()\n",
    "    loop_items = []\n",
    "    consumed_tokens = 1  # Already consumed the FOR token\n",
    "    \n",
    "    while tokens and tokens[0].type != 'ENDFOR':\n",
    "        token = tokens.pop(0)\n",
    "        consumed_tokens += 1\n",
    "        \n",
    "        if token.type == 'TEXT' or token.type == 'EXPRESSION':\n",
    "            # Similar handling as in parse_message\n",
    "            tokens.insert(0, token)\n",
    "            nested_items = parse_template_items(tokens)\n",
    "            loop_items.extend(nested_items)\n",
    "            consumed_tokens += len(nested_items)\n",
    "        # Extend this to handle nested structures\n",
    "    \n",
    "    # Skip the ENDFOR token\n",
    "    if tokens and tokens[0].type == 'ENDFOR':\n",
    "        consumed_tokens += 1\n",
    "        tokens.pop(0)\n",
    "    \n",
    "    return (TemplateLoop(iterator=iterator, iterable=iterable, template=loop_items), consumed_tokens)\n",
    "\n",
    "# Now, use the parser function on the list of tokens from step 1\n",
    "# Example:\n",
    "template_structure = parse(tokens)\n",
    "print(template_structure.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prooompt-WmAyYwYX-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
